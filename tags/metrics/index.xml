<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Metrics on Technology Blog</title>
    <link>https://nttdata-dach.github.io/tags/metrics/</link>
    <description>Recent content in Metrics on Technology Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright 2025 NTT DATA Deutschland SE - This site does not use any cookies</copyright>
    <lastBuildDate>Thu, 12 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://nttdata-dach.github.io/tags/metrics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hazelcast Metrics via Prometheus</title>
      <link>https://nttdata-dach.github.io/posts/rd-hazelcastmetricsviaprometheus/</link>
      <pubDate>Thu, 12 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://nttdata-dach.github.io/posts/rd-hazelcastmetricsviaprometheus/</guid>
      <description>A step-by-step guide on how to collect Hazelcast metrics via Prometheus. The tutorial is aimed at those who are running a customized Hazelcast microservice, rather than the full-blown zip-file/dockers. The guide covers all the necessary steps, from adding the Prometheus dependency to Java code configuration, updating application YAML and Dockerfile, to updating the ServiceMonitor. The article also offers helpful hints and sources for further reading.</description>
    </item>
    <item>
      <title>Part 3: Enabling annotation-based scraping</title>
      <link>https://nttdata-dach.github.io/posts/mjm-sa-otelmetrics-03-annotationbasedscraping/</link>
      <pubDate>Fri, 02 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://nttdata-dach.github.io/posts/mjm-sa-otelmetrics-03-annotationbasedscraping/</guid>
      <description>After showing how to get an OpenTelemetry Collector to support Prometheus CRDs as scrape targets, we discover how to integrate another well-known approach to mark workloads as scrape targets. Now, we focus on annotation-based scraping - what is it, when would we want to use it and how can we integrate it in our OpenTelemetry stack? In this article, we provide answers to all these questions, and more.</description>
    </item>
    <item>
      <title>Part 2: Scraping The First Metrics</title>
      <link>https://nttdata-dach.github.io/posts/mjm-sa-otelmetrics-02-firstmetrics/</link>
      <pubDate>Mon, 03 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://nttdata-dach.github.io/posts/mjm-sa-otelmetrics-02-firstmetrics/</guid>
      <description>Having explained the technical implementation of the monitoring stack in our latest blog post, this article focuses on replacing Prometheus with OpenTelemetry Collector to decouple scraping from the storage and query mechanisms. The OpenTelemetry Collector uses various building blocks to construct the telemetry pipeline and requires enabling of the target allocator. Guiding you through this process we provide various practical tips, including processor ordering and horizontal autoscaling.&amp;quot;</description>
    </item>
    <item>
      <title>Part 1: A Brief Introduction</title>
      <link>https://nttdata-dach.github.io/posts/mjm-sa-otelmetrics-01-intro/</link>
      <pubDate>Fri, 19 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://nttdata-dach.github.io/posts/mjm-sa-otelmetrics-01-intro/</guid>
      <description>With this blog post, we kick off a series on evolving our Kubernetes metrics stack. Our journey to replace Prometheus with an OpenTelemetry solution begins with an introduction OpenTelemetry and why we see it as a valid alternative to our current implementation. After explaining the main parts of the OpenTelemetry project and briefly reviewing its history, we discuss the pros and cons. After reading this, you will be able to follow along our hands-on and deep-tech posts on how we optimize our metrics stack.</description>
    </item>
  </channel>
</rss>
